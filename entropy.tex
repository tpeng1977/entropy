% Pure theory paper: (i) mirror-state paradox vs monotonic entropy increase
%                  (ii) first-principles proof that constraints reshape P(S;lambda)

\documentclass[11pt,a4paper]{article}
\usepackage[margin=2.5cm]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{hyperref}
\emergencystretch=1em

\title{Entropy Has No Direction: Constraint Engineering Reshapes Entropy Distributions and Paves the Way for Energy Freedom}
\author{Ting Peng\\
  \texttt{t.peng@ieee.org}\\
  ORCID: \href{https://orcid.org/0009-0001-9059-2278}{0009-0001-9059-2278}\\
  Key Laboratory for Special Area Highway Engineering of Ministry of Education,\\
  Chang'an University, Xi'an 710064, China}
\date{\today}

\begin{document}
\maketitle

\noindent\footnotesize The \LaTeX\ source of this manuscript, together with a live FAQ, is available at \url{https://github.com/tpeng1977/entropy}.

\begin{abstract}
The central conclusion of this paper is that \textbf{constraints change the
system's operating characteristics and reshape the entropy distribution}. From
four axioms of classical mechanics and statistical mechanics (Hamiltonian
dynamics, time-reversal invariance, Boltzmann coarse-grained entropy,
phase-space and invariant measure), we derive two results that support this
conclusion. First, a mirror-state construction: for any microstate $A$ one
constructs its time-reversed partner $B$ (Axiom~2). Any universal statement that
entropy does not decrease forward in time, applied to both $A$ and $B$, implies
that entropy is constant on every trajectory; universal monotonicity is therefore
incompatible with Axioms~1--3. Second, from Axiom~4 we prove that constraints
necessarily reshape the long-time entropy distribution
$P_{\infty}(S;\lambda)$ by altering the invariant measure through the Hamiltonian
and/or the accessible phase space. Constraints, as the core variable of engineering
design, thus relax the long-standing limit of entropy increase and pave a
brand-new path for human energy freedom. A sharp microcanonical criterion is given;
recent experimental work validates the framework. The energy crisis has
become a core bottleneck restricting the sustainable development of human
civilisation. This research challenges traditional thermodynamic fatalism and
opens the era of thermodynamic design, with profound
significance for the long-term survival and development of humanity.
\end{abstract}

\section{Introduction}

To enable safe, comfortable, and rapid travel, we have overcome geological and
environmental obstacles, spanned natural chasms, and turned the impossible into
the possible---building highways, railways, and airports on a vast scale. These
achievements stand as a cornerstone of civilisation. They rest on a single
principle: constraints reshape what is accessible, and thus what becomes
typical. This paper reconstructs the core cognition of entropy evolution from
this perspective of engineering constraint design and shows that the same
principle extends from macroscopic engineering to the foundations of
thermodynamics. Its most important conclusion is that \textbf{constraints
change the system's operating characteristics and reshape the entropy
distribution}.

The energy crisis has become a core bottleneck restricting the sustainable
development of human civilisation. Abundant thermal energy surrounds us; if it
can be harnessed and put to fuller use, we may achieve energy freedom; if the
universe is destined for heat death, that possibility is foreclosed. Driven by
the desire to make fuller use of thermal energy and the refusal to accept the
heat-death thesis, we take
logic and mathematics as our tools and embark on this technical exploration. We
take as our sole basis four axioms (Sec.~\ref{sec:prelim}): Hamiltonian
dynamics (Axiom~1), time-reversal invariance (Axiom~2), Boltzmann coarse-grained
entropy (Axiom~3), and phase-space and invariant measure (Axiom~4). No other laws
or postulates are invoked.

From these four axioms we derive two results and prove that entropy has no
intrinsic direction. (i)~\textbf{Entropy has no direction.} A
mirror-state construction (Axioms~1--3) shows that any universal statement of the
form ``entropy does not decrease forward in time'' (trajectory-wise or as a
universal statistical principle) is incompatible with the axioms; the derived picture is that entropy is described by a
probability distribution $P(S)$, without an intrinsic direction. (ii)~\textbf{Constraints
and boundary conditions reshape this distribution.} From Axiom~4 we prove that
constraints reshape the long-time entropy distribution
$P_{\infty}(S;\lambda)$. Constraints, as the core variable of engineering
design, thus relax the long-standing limit of entropy increase and pave a
brand-new path for human energy freedom; the main takeaway is that constraints change the
system's operating characteristics and reshape the entropy distribution. The
proof of (ii) was motivated in part by the author's earlier simulation work showing that geometry can alter entropy regimes in
nanofluidic cascades~\cite{peng2026geometrychallengesentropyregimedependentrectification}.
We then discuss recent experimental work that validates this framework. This research challenges traditional thermodynamic fatalism and opens the era of
thermodynamic design, which is of profound significance to the long-term
survival and development of human beings.

\section{Axioms}
\label{sec:prelim}

The entire paper relies only on the following four axioms of classical mechanics
and statistical mechanics. No other laws or postulates are used.

\paragraph{Axiom 1 (Hamiltonian dynamics).}
The microscopic evolution of an isolated system obeys classical Hamiltonian dynamics.
The phase-space microstate $\Gamma(t)$ satisfies Hamilton's equations
$\dot{\Gamma}=\{H,\Gamma\}$, where $H$ is the system Hamiltonian and
$\{\cdot,\cdot\}$ denotes the Poisson bracket.

\paragraph{Axiom 2 (Time-reversal invariance).}
There exists a time-reversal operator $\mathcal{T}$ (for classical mechanics:
reverse all momenta, leave positions unchanged). If $\Gamma_A(t)$ is a solution of
Hamilton's equations, then the mirror state
$\Gamma_B(t):=\mathcal{T}\Gamma_A(2t_0-t)$ is also a solution of the same
Hamilton's equations for any fixed $t_0$. In particular, the forward-time
evolution of $\Gamma_B(t_0)=\mathcal{T}\Gamma_A(t_0)$ replays the past of
$\Gamma_A$ in reverse.

\paragraph{Axiom 3 (Boltzmann coarse-grained entropy).}
Phase space is partitioned by a time-reversal symmetric coarse-graining
$\{C_m\}_{m\in\mathcal{M}}$ (i.e.\ $\mathcal{T}C_m=C_m$ for each macrostate
$C_m$). The Boltzmann entropy of macrostate $C_m$ is
$S_m=k_B\ln(W_m/W_0)$, where $W_m$ is the phase-space volume of $C_m$ and
$W_0>0$ is an arbitrary reference volume (shifting by a constant does not affect
any conclusions). The instantaneous entropy of the system is
$S(\Gamma)=S_m$ if and only if $\Gamma\in C_m$; equivalently,
$S(\mathcal{T}\Gamma)=S(\Gamma)$.

For the derivation of $P_{\infty}(S;\lambda)$ we use the energy-shell form: at
fixed energy $E$, $W_m^{(E)}$ is the accessible volume of $C_m$ on the energy
shell, and $S_m^{(E)}=k_B\ln(W_m^{(E)}/W_0)$.

\paragraph{Axiom 4 (Phase space and invariant measure).}
Phase-space evolution satisfies Liouville's theorem (measure is conserved). The
long-time invariant measure is determined solely by the Hamiltonian and the
accessible phase space: for an isolated system at fixed energy $E$, the invariant
measure is microcanonical (uniform on the accessible energy shell); for a system
coupled to a heat bath at temperature $T$, the invariant measure is canonical
(Gibbs with that Hamiltonian and $\beta=1/(k_B T)$).

\paragraph{Remark (continuous or discrete).}
\label{sec:continuity}
The mirror-state argument below holds \emph{whether $S(t):=S(\Gamma(t))$ is
continuous along trajectories or not}. If it is continuous (smooth
coarse-graining), then ``every time is a local minimum'' implies $S(t)$ is
constant. If it is piecewise constant with jumps (discrete coarse-graining),
Eq.~\eqref{eq:two_sided_min} still forces $S(t_0)$ to be a two-sided minimum at
every $t_0$, ruling out any jump up or down, so again $S(t)$ is constant. The
conclusion is the same in both cases.

\subsection{Interpretation of $P_{\infty}(S;\lambda)$}
\label{sec:Pinf_meaning}

In the second part of the paper, $P_{\infty}(S;\lambda)$ denotes the
\emph{long-time} entropy distribution induced by the invariant measure of Axiom~4.
Under ergodicity or when the initial ensemble is drawn from the invariant measure,
$P_{\infty}$ is the limiting distribution of $S$ over long time. The formulas
below are statements about these invariant measures and the entropy
distributions they induce.

\section{The mirror-state paradox}
\label{sec:paradox}

\subsection{Strict (trajectory-wise) monotonicity is impossible as a universal law}

\textbf{Claim.} From Axioms~1--3 (Sec.~\ref{sec:prelim}), a universal statement of
the form ``for every microstate and every time,
$S(t+\delta t)\ge S(t)$ for all sufficiently small $\delta t>0$'' is
incompatible.

\textit{Proof (mirror-state construction).}
Fix an arbitrary time $t_0$ on an arbitrary trajectory $\Gamma_A(t)$. Construct the
mirror state at the same time: $\Gamma_B(t_0)=\mathcal{T}\Gamma_A(t_0)$, and let
$\Gamma_B(t)$ be its forward-time evolution. By Axiom~2, for any
$\delta t>0$,
\[
\Gamma_B(t_0+\delta t)=\mathcal{T}\Gamma_A(t_0-\delta t).
\]
By Axiom~3, $S(\mathcal{T}\Gamma)=S(\Gamma)$,
so
\[
S_B(t_0+\delta t)=S_A(t_0-\delta t),
\qquad
S_B(t_0)=S_A(t_0).
\]
Now apply the universal monotonicity statement to \emph{both} $A$ and $B$:
\[
S_A(t_0+\delta t)\ge S_A(t_0),
\qquad
S_B(t_0+\delta t)\ge S_B(t_0).
\]
The second inequality becomes $S_A(t_0-\delta t)\ge S_A(t_0)$. Hence, for all small
$\delta t>0$,
\begin{equation}
S_A(t_0+\delta t)\ge S_A(t_0)
\quad\text{and}\quad
S_A(t_0-\delta t)\ge S_A(t_0).
\label{eq:two_sided_min}
\end{equation}
Thus $t_0$ is a (two-sided) local minimum of $S_A(t)$.

Because $t_0$ was arbitrary, \emph{every} time is a local minimum. Whether
$S_A(t)$ is continuous or piecewise constant (Sec.~\ref{sec:continuity}), a
function for which every time is a two-sided local minimum must be constant.
Therefore any universal statement that entropy does not decrease along every
trajectory would imply that entropy is constant on every trajectory, eliminating
any entropic arrow of time. \hfill $\square$

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{fig_mirror_paradox.pdf}
\caption{The mirror-state paradox.
\textbf{(a)}~For any trajectory $S_A(t)$ (solid blue) and its time-reversed
partner $S_B(t)=S_A(2t_0-t)$ (dashed red), universal monotonicity would require
both $\Delta S_A\ge 0$ and $\Delta S_B\ge 0$ forward from $t_0$.
Because $S_B(t_0+\delta t)=S_A(t_0-\delta t)$, the second condition forces
$S_A$ to be non-decreasing \emph{backward} as well, making $t_0$ a two-sided
local minimum.
\textbf{(b)}~Since $t_0$ is arbitrary, every point must be a local minimum;
whether $S(t)$ is continuous or not, this implies $S(t)=\mathrm{const}$,
contradicting observed entropy changes.}
\label{fig:mirror}
\end{figure}

\subsection{Extension: universal statistical monotonicity is likewise incompatible}
\label{sec:stat}

The same mirror-state logic shows that a \emph{universal} statistical principle
``entropy increase is overwhelmingly probable for the forward-time evolution of
any initial microstate'' is incompatible with time-reversal invariance. Apply
that principle to $A$ at time $t_0$, and also to $B=\mathcal{T}A$ at $t_0$. Since
the forward evolution of $B$ corresponds to the time-reversed past of $A$,
``overwhelmingly probable increase'' for both implies (with overwhelming probability)
the two-sided inequalities in Eq.~\eqref{eq:two_sided_min}, i.e. that $t_0$ is a
local minimum with overwhelming probability. Choosing $t_0$ arbitrarily removes any
persistent arrow of time in the same way.

Thus, from Axioms~1--3, no universal one-way statement about $\Delta S$ can hold
for every microstate; any such statement must depend on additional structure
(initial ensemble, coarse-graining, limits, or constraints/boundaries). This
leads to the derived view below.

\section{Derived view: entropy is a random variable\\with a constraint-dependent PDF}
\label{sec:corrected}

From the preceding derivation, the picture is:
\textbf{entropy has no direction; it has a probability distribution}.
Write $P_t(S)$ for the (time-dependent) entropy distribution induced by an
ensemble of microstates at time $t$, and $P_{\infty}(S;\lambda)$ for the long-time
distribution under constraint parameters $\lambda$ (geometry, boundary conditions,
static fields, etc.).

At the microscopic level, however, nothing in the dynamics ``sees'' entropy.
Individual particles obey time-reversal invariant equations of motion; their
trajectories and interactions are governed by the Hamiltonian and forces, not by
macroscopic state functions such as entropy. Boltzmann entropy is a coarse-grained,
statistical description of the collective behaviour of many particles---a
macroscopic \emph{appearance} of the underlying time-reversal invariant motion,
obtained only after we partition phase space into macrostates and count accessible
microstates. Constraints cannot change the fundamental microscopic rules; their
core role is to intervene directly in the actual motion of particles by changing
the Hamiltonian $H(\Gamma;\lambda)$ and/or the accessible set
$\mathcal{A}(\lambda)$, thereby restricting where particles can go and how they
move. This, in turn, changes the number of accessible microstates for each
macrostate and thus reshapes the entropy distribution. All changes in entropy are
therefore \emph{statistical summaries} of how constraints redirect microscopic
trajectories. Entropy is a diagnostic, not a causal driver. In practical
engineering terms, what one truly controls and optimises are constraints and
boundary conditions (to achieve, say, separation or mixing), while entropy is
useful as a bookkeeping tool for whether a given design makes certain macrostates
typical or rare. From a logical perspective it is more meaningful to study how
different constraints alter system dynamics and long-time distributions than to
postulate universal laws about ``entropy increase'' detached from the underlying
microphysics.

From this angle, familiar macroscopic ``entropy increase'' phenomena are best
understood as follows. In many textbook and laboratory situations, the initial
state is prepared to be \emph{very special} and low-entropy (gas in one half of
a box, sharp temperature gradients, unmixed components, etc.). Starting from such
atypical initial conditions, the entropy---as a coarse-grained statistic of
particle configurations---does indeed rise rapidly toward the values typical of
the long-time distribution under the given constraints. Once the system has
reached that regime, however, the entropy does not freeze at a single ``equilibrium
value'': microscopic dynamics continue indefinitely and $S(t)$ keeps fluctuating,
with spontaneous increases and decreases both being normal. The role of constraints
is to determine the \emph{shape} of the long-time distribution for $S$ (and for
other observables), not to enforce monotone drift toward a uniquely defined maximum.
There need not be a strict equilibrium state in the sense of a single entropy
value, nor must the formal ``maximum entropy'' compatible with constraints coincide
with the most probable coarse-grained macrostate once dynamical restrictions are
taken seriously.

What fundamentally decides whether a system mixes, separates, or self-organises
into ordered patterns is therefore the constraint-dependent microscopic dynamics
and the resulting invariant measures. All results in this paper concerning entropy
distributions and their evolution should thus be read as probabilistic,
ensemble-level characterisations of typical behaviour under specified constraints,
rather than as per-trajectory guarantees for every single realisation of a physical
system.

The remainder of this paper proves the second core claim---\textbf{constraints and
boundaries can change the long-time entropy distribution
$P_{\infty}(S;\lambda)$} in an explicit, first-principles way---and then presents
experimental validation of this framework.

\section{First-principles derivation: constraints $\lambda \to P_{\infty}(S;\lambda)$}
\label{sec:constraint_to_P}

This section uses Axioms~1, 3 and 4 to derive how constraint parameters
$\lambda$ determine the long-time entropy distribution $P_{\infty}(S;\lambda)$.

\subsection{Constraints as Hamiltonian/accessible-set modifications}

Let $\lambda$ denote constraint parameters. Constraints enter through the Hamiltonian
\begin{equation}
H(\Gamma;\lambda)=H_0(\Gamma)+V_{\mathrm{c}}(\Gamma;\lambda),
\label{eq:H_constraint}
\end{equation}
and/or through an accessible set $\mathcal{A}(\lambda)$ (hard constraints). Both
views are equivalent: hard walls correspond to $V_{\mathrm{c}}=+\infty$ outside
$\mathcal{A}(\lambda)$.

\subsection{Long-time invariant measures (microcanonical and canonical)}

By Axiom~4, the invariant measure is determined solely by the Hamiltonian and
the accessible phase space. We make this explicit for the two standard cases.

\paragraph{Microcanonical (isolated).}
At fixed energy $E$, the invariant measure is uniform on the accessible energy shell:
\begin{equation}
\rho_{\infty}^{(E)}(\Gamma;\lambda)=
\frac{1}{\Omega(E;\lambda)}\,
\delta\!\bigl(H(\Gamma;\lambda)-E\bigr)\,
\mathbf{1}_{\mathcal{A}(\lambda)}(\Gamma),
\label{eq:rho_micro}
\end{equation}
where the accessible density of states is
\begin{equation}
\Omega(E;\lambda)=
\int \mathrm{d}\Gamma\,
\delta\!\bigl(H(\Gamma;\lambda)-E\bigr)\,
\mathbf{1}_{\mathcal{A}(\lambda)}(\Gamma).
\label{eq:Omega_entropy}
\end{equation}

\paragraph{Canonical (heat bath).}
With a heat bath at temperature $T$ and dynamics obeying fluctuation--dissipation,
the invariant measure is
\begin{equation}
\rho_{\infty}(\Gamma;\lambda)=
\frac{1}{Z(\lambda)}\,e^{-\beta H(\Gamma;\lambda)},
\qquad
Z(\lambda)=\int_{\Gamma\in\mathcal{A}(\lambda)} \mathrm{d}\Gamma\,
e^{-\beta H(\Gamma;\lambda)}.
\label{eq:rho_can}
\end{equation}

\subsection{Boltzmann entropy on the energy shell}

Fix a time-reversal symmetric coarse-graining $\{C_m\}_{m\in\mathcal{M}}$ (Axiom~3).
Define the accessible macrostate volume on the energy shell:
\begin{equation}
W_m^{(E)}(\lambda)=
\int \mathrm{d}\Gamma\,
\delta\!\bigl(H(\Gamma;\lambda)-E\bigr)\,
\mathbf{1}_{C_m}(\Gamma)\,
\mathbf{1}_{\mathcal{A}(\lambda)}(\Gamma),
\label{eq:WmE_entropy}
\end{equation}
and assign the Boltzmann entropy value
\begin{equation}
S_m^{(E)}(\lambda)=k_B\ln\!\left(\frac{W_m^{(E)}(\lambda)}{W_0}\right).
\label{eq:SmE_entropy}
\end{equation}

\subsection{Closed-form expression for $P_{\infty}(S;\lambda)$ and a sharp change criterion}

\paragraph{Microcanonical.}
Because the microcanonical measure is uniform on the energy shell, the macrostate
probability is a ratio of accessible volumes:
\begin{equation}
\pi_m^{(E)}(\lambda)=\frac{W_m^{(E)}(\lambda)}{\Omega(E;\lambda)},
\qquad
\Omega(E;\lambda)=\sum_{m\in\mathcal{M}}W_m^{(E)}(\lambda).
\label{eq:pi_micro_entropy}
\end{equation}
Therefore the long-time entropy distribution at fixed energy is
\begin{equation}
\boxed{
P_{\infty}^{(E)}(S;\lambda)=
\sum_{m\in\mathcal{M}}
\frac{W_m^{(E)}(\lambda)}{\Omega(E;\lambda)}\,
\delta\!\bigl(S-S_m^{(E)}(\lambda)\bigr).
}
\label{eq:PS_micro_entropy}
\end{equation}

\textbf{Proposition (sharp criterion; ``only translation'' degeneracy).}
Fix $E$ and the coarse-graining. Let $\mathcal{V}(\lambda)$ denote the multiset of
accessible macrostate volumes $\{W_m^{(E)}(\lambda)\}_{m\in\mathcal{M}}$ (counting multiplicity).
\begin{enumerate}
  \item If there exists $c>0$ such that $\mathcal{V}(\lambda_2)=c\,\mathcal{V}(\lambda_1)$
  (i.e. all macrostate volumes scale by a common factor, up to permutation), then
  \[
  P_{\infty}^{(E)}(S;\lambda_2)=P_{\infty}^{(E)}\!\left(S-k_B\ln c\,;\lambda_1\right),
  \]
  i.e. the distribution changes only by translation of the entropy axis.
  \item Otherwise, $P_{\infty}^{(E)}(S;\lambda_2)$ is \emph{not} a translate of
  $P_{\infty}^{(E)}(S;\lambda_1)$; the distribution changes structurally.
\end{enumerate}

\textit{Proof.}
Let $M$ be the macrostate index with $\mathbb{P}(M=m)=\pi_m^{(E)}(\lambda)$ and define
$X_\lambda:=W_M^{(E)}(\lambda)$. Then $S=k_B\ln(X_\lambda/W_0)$ and
Eq.~\eqref{eq:PS_micro_entropy} is exactly the law of $S$.
If $W_m^{(E)}(\lambda_2)=c\,W_{\sigma(m)}^{(E)}(\lambda_1)$ for some permutation $\sigma$, then
$X_{\lambda_2}\overset{d}{=}c\,X_{\lambda_1}$, hence
$S_{\lambda_2}\overset{d}{=}S_{\lambda_1}+k_B\ln c$, which is the claimed translation.
Conversely, if $P_{\infty}^{(E)}(S;\lambda_2)$ were a translate of $P_{\infty}^{(E)}(S;\lambda_1)$ by
$\Delta$, then $X_{\lambda_2}=W_0 e^{S/k_B}$ would be distributed as $e^{\Delta/k_B}X_{\lambda_1}$,
which implies $\mathcal{V}(\lambda_2)=e^{\Delta/k_B}\mathcal{V}(\lambda_1)$ (up to permutation).
\hfill $\square$

\begin{figure}[t]
\centering
\includegraphics[width=\textwidth]{fig_distribution_change.pdf}
\caption{How constraints reshape the long-time entropy distribution
$P_{\infty}^{(E)}(S;\lambda)$. Here $P_\infty$ is the \emph{distribution} of
entropy over long time; the system keeps fluctuating and there is no single
equilibrium state. \textbf{(a)}~When all macrostate volumes scale by a common
factor~$c$, the distribution translates along the $S$-axis by $k_B\ln c$
without changing shape (the only degenerate case in the sharp criterion).
\textbf{(b)}~Unconstrained case: entropy is almost entirely concentrated
near the \emph{maximum} $S_{\max}$ (narrow peak at high $S$). Under a
generic constraint the distribution reshapes: significant probability
mass moves to lower $S$, making lower-entropy
macrostates statistically accessible.}
\label{fig:Pinf}
\end{figure}

\paragraph{Canonical as an exact energy mixture.}
The canonical energy density is
\begin{equation}
P_\beta(E;\lambda)=\frac{\Omega(E;\lambda)\,e^{-\beta E}}{Z(\lambda)},
\qquad
Z(\lambda)=\int \mathrm{d}E\;\Omega(E;\lambda)\,e^{-\beta E}.
\label{eq:PE_entropy}
\end{equation}
Since $P_{\infty}^{(E)}(S;\lambda)$ is the entropy distribution conditioned on energy $E$,
the canonical long-time entropy distribution is the exact mixture
\begin{equation}
\boxed{
P_{\infty,\beta}(S;\lambda)=\int \mathrm{d}E\;P_\beta(E;\lambda)\,P_{\infty}^{(E)}(S;\lambda).
}
\label{eq:PS_can_mix_entropy}
\end{equation}

\subsection{Bulletproof qualifier: changing rates is not changing the invariant measure}

The above results concern changes that alter the invariant measure by changing
$\mathcal{A}(\lambda)$ and/or $H(\Gamma;\lambda)$.
By contrast, a purely kinetic modification that only rescales crossing rates or
mixing times \emph{while leaving the invariant measure unchanged} can change the
finite-time distribution $P_t(S)$ but does not change the long-time distribution
$P_{\infty}(S)$.

\section{Experimental validation: asymmetric constraints enable spontaneous low-entropy transitions}
\label{sec:experimental}

Recent experimental work by Qiao and Wang~\cite{qiao2025intrinsicnonequilibriumdistributionlarge}
provides compelling validation of the theoretical framework presented above. Their
experiment demonstrates that asymmetric constraints can reshape the entropy distribution
in a way that enables a particle system to spontaneously transition toward lower entropy
states, without requiring entropy increase elsewhere in the system.

\subsection{The Qiao--Wang experiment}

Qiao and Wang investigated nanoporous carbon electrodes in dilute aqueous CsPiv
solutions where the effective nanopore size ($d_e \approx 1$\,nm) only slightly
exceeds the ion size ($d_i \approx 0.7$\,nm), satisfying $d_i < d_e < 2d_i$.
The steady-state ion distribution is intrinsically non-equilibrium: the measured
$|\delta V|$ is nearly an order of magnitude above the upper limit that
equilibrium thermodynamics would assign to such a system, and the system produces
useful work in an isothermal cycle by absorbing heat from a single thermal reservoir.

\subsection{Interpretation: constraint-reshaped $P_{\infty}(S;\lambda)$}

In our framework the nanopore walls act as the constraint parameter $\lambda$
that reshapes $\mathcal{A}(\lambda)$. The quasi-one-dimensional confinement
fundamentally alters $W_m^{(E)}(\lambda)$: ion trajectories lose full
chaoticity, collisions become sparse, and the system cannot relax to global
equilibrium---a structural change in $P_{\infty}^{(E)}(S;\lambda)$ per the
sharp criterion of Sec.~\ref{sec:constraint_to_P}. The observed
non-Boltzmannian surface-ion density $\sigma^{\pm}$ is a direct manifestation:
the constraint prevents the system from reaching $S_{\text{eq}}$ and instead
pins it at $S_{\text{ne}} < S_{\text{eq}}$, without requiring compensating
entropy increase elsewhere. It is the entropy landscape itself that has been
reshaped, not the entropy balance between subsystems.

\subsection{Further experimental support from the literature}

Independent work by other groups is consistent with the same mechanism.
Ramirez, Gomez, Mafe and coworkers~\cite{ramirez2015energyconversionfluctuating,gomez2015chargingcapacitor} showed that asymmetric conical nanopores rectify a zero-mean fluctuating voltage into a net ionic current, charging an external capacitor to about 1\,V; the constraint $\lambda$ (pore geometry) makes the long-time charge-transfer distribution asymmetric under sign flip of the drive. Qiao, Shang, and Kou~\cite{qiao2021moleculargate} demonstrated a molecular-sized gate (locally nonchaotic barrier) in an isolated system, where gas spontaneously flows from the low-pressure to the high-pressure side and useful work can be extracted in a cycle from a single thermal reservoir---the same constraint-reshaping picture in a different geometry. Powell, Vlassiouk, and Siwy~\cite{powell2009nonequilibrium1f} reported voltage-polarity-dependent nonequilibrium 1/f noise in rectifying nanopores (Phys.\ Rev.\ Lett.): under one polarity the system exhibits equilibrium-like fluctuations, under the other distinctly non-equilibrium fluctuations, illustrating how $\lambda$ shapes not only the mean current but the fluctuation spectrum. Together with the Qiao--Wang result, these experiments show that constraint-reshaped entropy distributions are not an isolated finding but a recurring pattern across nanoscale systems.

\subsection{Macroscopic engineering validation: Constraint-induced entropy shaping in civil engineering and transport}

Beyond the microscopic nanopore experiment, the framework of constraint-reshaped
$P_{\infty}(S;\lambda)$ has been implicitly validated by the long history of
practice in civil engineering and transport (the author's core research field).
For desert roads, asymmetric windbreak forest belts (constraint parameter
$\lambda_1$) act as geometric boundaries that reshape the phase space of sand
particle motion: the accessible macrostate volume for sand deposition on the
pavement is drastically reduced, while the volume for sand accumulation
outside the forest belt is expanded. This structural change in macrostate volumes
(per the sharp criterion in Sec.~\ref{sec:constraint_to_P}) reshapes the
long-time entropy distribution of the sand--wind system, making the low-entropy
state (road unobstructed, ordered sand motion) the statistically dominant
macrostate instead of the high-entropy random sand deposition.

Similarly, for river-crossing roads, spur dikes and longitudinal dikes
(constraint parameter $\lambda_2$) alter the Hamiltonian of water flow by
changing the flow field and energy dissipation, reshaping the entropy
distribution of the water--sediment system. The constrained flow field reduces
the accessible macrostate volume for high-energy scouring of bridge
piers, shifting the long-time distribution $P_{\infty}(S;\lambda_2)$ toward
lower entropy (stable flow, no structural damage). In both cases, these
civil engineering and transport measures do not ``fight against entropy increase'' in the traditional
thermodynamic sense, but instead design specific constraints to reshape the
entropy landscape---the same core mechanism as the nanopore experiment, just
scaled to macroscopic geophysical systems.

These engineering practices confirm that constraint-reshaped entropy
distribution is not a microscopic peculiarity but a universal principle
applicable to all complex systems, from nanoscale ion motion to macroscale
geophysical dynamics. Windbreaks, dikes, vortex suppression, and
vehicle--road coordination have repeatedly achieved ordered, low-entropy
outcomes through constraint design alone.

\section{Conclusion}

\textbf{The most important conclusion of this work is that constraints change the
system's operating characteristics and reshape the entropy distribution.}
Constraints fix the accessible phase space and the Hamiltonian (and thus how the
system evolves); they thereby alter the invariant measure and the
long-time entropy distribution $P_{\infty}(S;\lambda)$. This is proved from the
four axioms of Sec.~\ref{sec:prelim}, with a sharp microcanonical criterion that
isolates the only degenerate case of mere translation. Entropy has no intrinsic
direction: it is described by a probability distribution $P(S)$ that depends on
constraints and boundary conditions, as shown by the mirror-state construction
(Axioms~1--3). This work was driven by the desire for energy freedom and the
refusal to accept the heat-death thesis.

A concise way to summarise the conceptual stance of this work is: \emph{constraints
set the landscape} (they fix the accessible phase space and the Hamiltonian, and thus
which macrostates are possible); \emph{dynamics set the rules} (time-reversal invariant
microscopic evolution governs how particles move, independent of entropy);
\emph{stochasticity---or in quantum mechanics, intrinsic indeterminacy---determines
which of the accessible states is realised}; and \emph{entropy is only a reading}, a
coarse-grained statistic of the current macrostate, not a driver of the dynamics. In
that picture, the future is not predetermined by a single entropic fate: under different
constraints, different futures---mixing, separation, or self-organization---become
possible, and each regime remains open to design. Every day is new.

This pattern---constraints reshaping the entropy landscape and enabling spontaneous
formation of structure---is familiar from star and planet formation, crystal and
snowflake growth, mineral veins, and arguably the emergence of life: all instances of
constraint-induced local entropy decrease, consistent with the present framework.
It is also the core principle behind human engineering design in civil engineering and transport. 
Windbreak forests for desert roads, spur dikes for river-crossing roads, aerodynamic 
constraints for bridge vortex vibration suppression, and vehicle--road coordination 
technology for smoother traffic flow all achieve ordered, low-entropy system states 
(safe, unobstructed, and fluid traffic) by reshaping the entropy distribution of 
geophysical and traffic systems (sand--wind, water--sediment, wind--bridge coupling, 
and vehicle--road flow).

In this framework, whether a system can produce useful work in a cycle by
absorbing heat from a single thermal reservoir is determined by the constraints
and the resulting $P_{\infty}(S;\lambda)$; it is a limit-dependent,
model-dependent question. The possibility of harnessing abundant thermal energy
through constraint design is in that sense open in principle.

The experimental validation by Qiao and Wang~\cite{qiao2025intrinsicnonequilibriumdistributionlarge}
demonstrates that this possibility is not merely theoretical but has been
realised. Their work shows that asymmetric constraints can reshape the entropy
distribution to enable spontaneous low-entropy transitions, allowing a system to
produce useful work in a cycle by absorbing heat from a single thermal reservoir.
With this experimental confirmation, the fuller exploitation of thermal energy is
no longer only consistent with the derived framework but has been achieved in the
laboratory.

The path forward is clear: through iterative enhancement, engineering optimisation,
and scaling of constraint-based entropy reshaping, practical means to harness
thermal energy can be developed. The implications extend far beyond energy generation. Because
constraints can perpetually reshape entropy distributions and enable spontaneous
order, the macroscopic world need not tend toward a featureless equilibrium:
universal heat death is not a foregone conclusion but an artefact of the
unconstrained limit. With this principle at hand, humanity can sustain civilisation
even through extended ice ages, ensuring the perpetual flourishing and development
of human culture. The macroscopic world will not end in silence; it will
continuously manifest various wonderful phenomena, sustained by the ever-present
possibility of constraint-induced order generation.

The era of thermodynamic fatalism is giving way to the age of thermodynamic design.
The end of thermodynamic fatalism means that human beings are no longer passive
acceptors of thermodynamic laws, but active designers of entropy evolution.
Through constraint engineering, we can not only realise energy freedom, but also
shape the ordered evolution of various complex systems, from nanoscale energy
devices to macroscale geophysical systems, and even the entire universe. This research points to a shift in which engineering science drives the
development of fundamental physics and human civilisation extends the scope of
what is possible within natural laws. That outcome answers the desire for energy freedom and the
refusal to accept the heat-death thesis with which we began.

%\section*{References (background)}
\begin{thebibliography}{13}
\bibitem{goldstein}
H.~Goldstein, C.~Poole, and J.~Safko,
\textit{Classical Mechanics} (Addison--Wesley, 3rd ed., 2002).

\bibitem{callen}
H.~B.~Callen,
\textit{Thermodynamics and an Introduction to Thermostatistics}
(Wiley, 2nd ed., 1985).

\bibitem{pathria}
R.~K.~Pathria and P.~D.~Beale,
\textit{Statistical Mechanics} (Elsevier, 3rd ed., 2011).

\bibitem{kubo}
R.~Kubo, M.~Toda, and N.~Hashitsume,
\textit{Statistical Physics II: Nonequilibrium Statistical Mechanics}
(Springer, 2nd ed., 1991).

\bibitem{lebowitz}
J.~L.~Lebowitz,
``Boltzmann's entropy and time's arrow,''
\textit{Physics Today} \textbf{46}(9), 32--38 (1993).

\bibitem{qiao2025intrinsicnonequilibriumdistributionlarge}
Y.~Qiao and M.~Wang,
``Breaking the boundaries of the second law of thermodynamics: Intrinsic nonequilibrium
distribution of large ions in charged small nanopores,''
arXiv:2407.04599 [cond-mat.soft] (2025).

\bibitem{peng2026geometrychallengesentropyregimedependentrectification}
T.~Peng,
``Geometry challenges entropy: Regime-dependent rectification in nanofluidic cascades,''
arXiv:2602.13931 [physics.comp-ph] (2026).

\bibitem{ramirez2015energyconversionfluctuating}
P.~Ramirez, P.~Gomez, J.~Cervera, S.~Nasir, M.~Ali, W.~Ensinger, and S.~Mafe,
``Energy conversion from external fluctuating signals based on asymmetric nanopores,''
\textit{Nano Energy} \textbf{16}, 375--382 (2015).

\bibitem{gomez2015chargingcapacitor}
V.~Gomez, P.~Ramirez, J.~Cervera, S.~Nasir, M.~Ali, W.~Ensinger, and S.~Mafe,
``Charging a capacitor from an external fluctuating potential using a single conical nanopore,''
\textit{Sci.\ Rep.} \textbf{5}, 9501 (2015).

\bibitem{qiao2021moleculargate}
Y.~Qiao, Z.~Shang, and R.~Kou,
``Molecular-sized outward-swinging gate: Experiment and theoretical analysis of a locally nonchaotic barrier,''
\textit{Phys.\ Rev.\ E} \textbf{104}, 064133 (2021);
arXiv:2106.06648.

\bibitem{powell2009nonequilibrium1f}
M.~R.~Powell, I.~Vlassiouk, C.~Martens, and Z.~S.~Siwy,
``Nonequilibrium 1/f noise in rectifying nanopores,''
\textit{Phys.\ Rev.\ Lett.} \textbf{103}, 248104 (2009).
\end{thebibliography}

\end{document}

