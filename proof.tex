% Theoretical extension: proof of the main conclusions of entropy.tex
% Scope: classical mechanics, cosmology, QM, particle physics, GR,
% nonequilibrium stat mech, condensed matter, QFT, open systems (Markovian
% and non-Markovian), quantum gravity (schematic), nuclear, plasma, fluid,
% information theory.

\documentclass[11pt,a4paper]{article}
\usepackage[margin=2.5cm]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{bm}
\usepackage{hyperref}
\emergencystretch=1em

\title{Theoretical Proof of the Main Conclusions of ``Entropy Has No Direction''\\
\large From Classical Mechanics to Quantum Gravity and Non-Markovian Open Systems}
\author{Supporting document to \texttt{entropy.tex}}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
This document provides a theoretical argument (proof scheme) for the two main conclusions of the companion paper \texttt{entropy.tex}: (i)~\textbf{entropy has no intrinsic direction}, and (ii)~\textbf{constraints change the system's operating characteristics and reshape the entropy distribution}. The \emph{classical} part is a complete, self-contained proof from four axioms (Sec.~\ref{sec:classical}); the remainder extends the same logic to cosmology, quantum mechanics, particle physics, general relativity, nonequilibrium statistical mechanics, condensed matter, quantum field theory, open quantum systems (Markovian and non-Markovian), quantum gravity (schematic), nuclear physics, plasma physics, fluid mechanics, and information theory (Shannon and algorithmic entropy). In each domain we show that either time-reversal symmetry holds and the mirror-state argument applies, or a breaking of that symmetry or a choice of constraints/initial conditions selects a direction---so that entropy never has a universal, law-like arrow. We do not assume any prior ``second law''; the only inputs are the axioms (classical) or the standard framework of each domain. Constraints consistently determine the long-time or steady-state entropy distribution. In each domain we use the standard notion of invariant measure (or long-time distribution) for that domain. A list of known physical domains and coverage is given at the end of the document.
\end{abstract}

\section{Statement of the main conclusions}
\label{sec:statement}

The companion paper \texttt{entropy.tex}~\cite{entropy} establishes from four classical axioms that: (A1) dynamics are Hamiltonian $\dot{\Gamma}=\{H,\Gamma\}$; (A2) the dynamics are time-reversal invariant; (A3) entropy is Boltzmann coarse-grained $S_m = k_B\ln(W_m/W_0)$ with $T$-symmetric macrostates; (A4) phase-space flow preserves the Liouville measure. The full classical derivation from these axioms is given in Sec.~\ref{sec:classical} below (see also \texttt{entropy.tex} for an equivalent derivation and figures). No second law or other thermodynamic postulate is used. From these it follows (in the classical setting) that:
\begin{enumerate}
  \item \textbf{Entropy has no intrinsic direction.} A mirror-state construction shows that any universal statement ``entropy does not decrease forward in time'' is incompatible with time-reversal invariant dynamics and time-reversal symmetric coarse-graining; entropy is therefore described by a probability distribution $P(S)$ over macrostates (or over time along a trajectory), without a built-in arrow.
  \item \textbf{Constraints change the system's operating characteristics and reshape the entropy distribution.} Constraint parameters $\lambda$ enter the Hamiltonian and/or the accessible phase space; the long-time entropy distribution $P_{\infty}(S;\lambda)$ is determined by the invariant measure and thus by $\lambda$. A sharp microcanonical criterion (Proposition in Sec.~\ref{sec:classical}: ``only translation'' degeneracy) characterises when the distribution changes only by translation along the $S$-axis versus structurally.
\end{enumerate}
By ``no intrinsic direction'' we mean that no universal law holds to the effect that entropy does not decrease (or increase) for every system regardless of constraints; by ``universal'' we mean holding for every system or every trajectory independent of the choice of constraints.

\paragraph{Core logic.}
The two conclusions hold across all domains for one reason: time-reversal either holds (then the mirror-state argument rules out any universal entropy arrow) or is broken (then any arrow comes from that breaking or from constraints), so entropy has no intrinsic direction; and in every domain the long-time or steady-state state or process distribution is fixed by constraints, while entropy is a statistical quantity of that distribution, so constraints reshape the entropy distribution.

In this document, ``entropy'' in each domain means the standard notion for that domain (e.g.\ Boltzmann coarse-grained classically, von Neumann or coarse-grained in QM, Bekenstein--Hawking for black holes, entropy production in fluctuation theorems). We argue that the two conclusions hold in classical mechanics (where they are derived in full in Sec.~\ref{sec:classical}; see also \texttt{entropy.tex}) and are strengthened when extended to cosmology, quantum mechanics, particle physics, general relativity, nonequilibrium statistical mechanics, and further domains (condensed matter, quantum field theory, open quantum systems, nuclear physics, plasma physics, fluid mechanics, information theory, and schematically quantum gravity and non-Markovian open systems). In each case we show that \emph{either} the same logic applies (time-reversal symmetry $\Rightarrow$ no universal entropy arrow; constraints $\Rightarrow$ reshape entropy), \emph{or} an explicit breaking (e.g.\ $T$-violation) or a choice of constraints/initial conditions selects a direction---so that the arrow is never a fundamental law of entropy itself.

\paragraph{Scope and coverage relative to existing physics.}
The proof explicitly covers: (1)~\textbf{classical mechanics}; (2)~\textbf{cosmology}; (3)~\textbf{quantum mechanics}; (4)~\textbf{particle physics}; (5)~\textbf{general relativity}; (6)~\textbf{nonequilibrium statistical mechanics}; (7)~\textbf{condensed matter and many-body physics}; (8)~\textbf{quantum field theory}; (9)~\textbf{open quantum systems} (Markovian and non-Markovian); (10)~\textbf{quantum gravity} (schematic, Sec.~\ref{sec:extended}); (11)~\textbf{nuclear physics} (Sec.~\ref{sec:nuclear-plasma-fluid-info}); (12)~\textbf{plasma physics}; (13)~\textbf{fluid mechanics}; (14)~\textbf{information theory} (Shannon and algorithmic entropy). All four (11--14) are in Sec.~\ref{sec:nuclear-plasma-fluid-info}. Domains such as acoustics, atmospheric and ocean dynamics, chemical kinetics, biophysics, and thermodynamics of computation follow the same pattern (constraints and dynamics fix the entropy description; no universal entropy law); they are not given separate sections here (to keep the document focused). See the end of the document for a list of known physical domains and coverage. In each domain we use the \emph{standard notion of invariant measure or long-time/steady-state distribution} for that domain (e.g.\ Liouville measure classically, diagonal ensemble or reduced equilibrium in QM, horizon area in semiclassical GR). The list (1)--(14) and the paragraph on known physical domains at the end together cover the main branches of current physics for the purposes of establishing (i) and (ii). No prior ``second law'' is invoked; the scope statement at the end of the document applies.

\paragraph{Natural examples (non-classical).}
The following three examples illustrate (i) and (ii) outside classical mechanics. (1)~\textbf{Cosmology:} The observed cosmic arrow (expansion, structure formation, radiation-to-matter transition) arises from the \emph{past hypothesis}---a constraint on initial conditions (the observable universe in a low-entropy state)---plus the dynamics; the entropy at later times is determined by this constraint and the Einstein equations, not by a universal law that entropy must increase. (2)~\textbf{Black hole:} Bekenstein--Hawking entropy $S_{\mathrm{BH}} = k_B A/(4\ell_P^2)$ is fixed by the horizon (a constraint: the accessible region for external observers); different horizon geometries (Schwarzschild, Kerr, charged) yield different $A$ and hence different $S_{\mathrm{BH}}$---constraints reshape the entropy. (3)~\textbf{Quantum entanglement:} For a bipartite system in a pure state $|\Psi_{AB}\rangle$, the von Neumann entropy of the reduced state $\rho_A = \mathrm{tr}_B |\Psi_{AB}\rangle\langle\Psi_{AB}|$ equals that of $\rho_B$; this entropy is not a property of the full system but of the \emph{partition} (constraint: which degrees of freedom are ``system'' vs ``environment''). Changing the partition reshapes the effective entropy---a direct instance of constraints reshaping the entropy distribution.

\section{Classical mechanics: complete proof}
\label{sec:classical}

The following is a self-contained derivation of (i) and (ii) in the classical setting from the four axioms (A1--A4) stated in Sec.~\ref{sec:statement}. No reference to the second law is made.

\subsection{Part (i): Entropy has no intrinsic direction (mirror-state argument)}

\textbf{Claim.} From Axioms~1--3 only, a universal statement of the form ``for every microstate and every time, $S(t+\delta t)\ge S(t)$ for all sufficiently small $\delta t>0$'' is incompatible with the axioms.

\textit{Proof (mirror-state construction).}
Fix an arbitrary time $t_0$ on an arbitrary trajectory $\Gamma_A(t)$. Construct the mirror state at the same time: $\Gamma_B(t_0)=\mathcal{T}\Gamma_A(t_0)$ (momenta reversed, positions unchanged), and let $\Gamma_B(t)$ denote its forward-time evolution under the same Hamiltonian. By Axiom~2 (time-reversal invariance), for any $\delta t>0$,
\[
\Gamma_B(t_0+\delta t)=\mathcal{T}\Gamma_A(t_0-\delta t).
\]
By Axiom~3, $S(\mathcal{T}\Gamma)=S(\Gamma)$ for the $T$-symmetric coarse-graining, so
\[
S_B(t_0+\delta t)=S_A(t_0-\delta t),\qquad S_B(t_0)=S_A(t_0).
\]
Apply the universal monotonicity statement to \emph{both} $A$ and $B$: $S_A(t_0+\delta t)\ge S_A(t_0)$ and $S_B(t_0+\delta t)\ge S_B(t_0)$. The second inequality gives $S_A(t_0-\delta t)\ge S_A(t_0)$. Hence for all small $\delta t>0$,
\begin{equation}
S_A(t_0+\delta t)\ge S_A(t_0)\quad\text{and}\quad S_A(t_0-\delta t)\ge S_A(t_0).
\label{eq:two_sided_min}
\end{equation}
Thus $t_0$ is a two-sided local minimum of $S_A(t)$. Because $t_0$ was arbitrary, \emph{every} time is a two-sided local minimum of $S_A(t)$.

\paragraph{Remark (continuous or discrete).}
This conclusion holds whether $S(t):=S(\Gamma(t))$ is continuous along trajectories or not. If $S(t)$ is continuous (smooth coarse-graining), then a function for which every time is a two-sided local minimum must be constant. If $S(t)$ is piecewise constant with jumps (discrete coarse-graining), \eqref{eq:two_sided_min} at every $t_0$ rules out any jump upward or downward at $t_0$, so again $S(t)$ is constant on every trajectory. In both cases, any universal trajectory-wise ``entropy does not decrease'' would imply entropy is constant on every trajectory, contradicting the existence of a nontrivial entropic arrow.

Therefore a universal law that entropy does not decrease forward in time is incompatible with Axioms~1--3. The same logic applies to a universal \emph{statistical} principle that entropy increase is overwhelmingly probable for every initial microstate: applying it to both $A$ and $B$ at $t_0$ again forces $t_0$ to be a local minimum with overwhelming probability; taking $t_0$ arbitrary removes any persistent arrow. \textbf{Hence, under $T$-invariant classical dynamics, entropy has no universal intrinsic direction;} it is described by a probability distribution $P(S)$ over macrostates (or over time along a trajectory). \hfill $\square$

\subsection{Part (ii): Constraints determine the invariant measure}

Phase-space flow preserves the Liouville measure (Axiom~4). The long-time invariant measure is determined solely by the Hamiltonian $H$ and the accessible set $\mathcal{A}$. Constraints enter through
\[
H(\Gamma;\lambda)=H_0(\Gamma)+V_{\mathrm{c}}(\Gamma;\lambda),\qquad \mathcal{A}(\lambda),
\]
where $\lambda$ denotes constraint parameters (e.g.\ geometry, boundaries); hard walls correspond to $V_{\mathrm{c}}=+\infty$ outside $\mathcal{A}(\lambda)$.

\paragraph{Microcanonical (isolated at energy $E$).}
The invariant measure is uniform on the accessible energy shell:
\[
\rho_{\infty}^{(E)}(\Gamma;\lambda)=\frac{1}{\Omega(E;\lambda)}\,\delta\bigl(H(\Gamma;\lambda)-E\bigr)\,\mathbf{1}_{\mathcal{A}(\lambda)}(\Gamma),
\]
where
\[
\Omega(E;\lambda)=\int \mathrm{d}\Gamma\;\delta\bigl(H(\Gamma;\lambda)-E\bigr)\,\mathbf{1}_{\mathcal{A}(\lambda)}(\Gamma).
\]

\paragraph{Canonical (coupled to heat bath at temperature $T$, $\beta=1/(k_B T)$).}
The invariant measure is
\[
\rho_{\infty}(\Gamma;\lambda)=\frac{1}{Z(\lambda)}\,e^{-\beta H(\Gamma;\lambda)},\qquad Z(\lambda)=\int_{\Gamma\in\mathcal{A}(\lambda)}\mathrm{d}\Gamma\;e^{-\beta H(\Gamma;\lambda)}.
\]

Under ergodicity, or when the initial ensemble is drawn from this invariant measure, the long-time distribution of any observable (including entropy $S$) coincides with the distribution induced by the invariant measure. When the system is not ergodic, the long-time statistics are still given by the invariant measure restricted to the trajectory's invariant set (e.g.\ the ergodic component), which is itself fixed by $H$ and $\mathcal{A}(\lambda)$. Thus \textbf{constraints} (encoded in $H(\Gamma;\lambda)$ and $\mathcal{A}(\lambda)$) \textbf{determine the invariant measure} and hence the long-time statistics of any observable, including entropy.

\subsection{Closed-form $P_{\infty}(S;\lambda)$ and sharp criterion}

Fix a time-reversal symmetric coarse-graining $\{C_m\}_{m\in\mathcal{M}}$ (Axiom~3). On the energy shell, the accessible volume of macrostate $C_m$ is
\[
W_m^{(E)}(\lambda)=\int \mathrm{d}\Gamma\;\delta\bigl(H(\Gamma;\lambda)-E\bigr)\,\mathbf{1}_{C_m}(\Gamma)\,\mathbf{1}_{\mathcal{A}(\lambda)}(\Gamma),
\]
and the Boltzmann entropy of that macrostate is $S_m^{(E)}(\lambda)=k_B\ln(W_m^{(E)}(\lambda)/W_0)$ with $W_0>0$ a reference volume. The macrostate probability under the microcanonical measure is $\pi_m^{(E)}(\lambda)=W_m^{(E)}(\lambda)/\Omega(E;\lambda)$, with $\Omega(E;\lambda)=\sum_m W_m^{(E)}(\lambda)$. Therefore the long-time entropy distribution at fixed energy $E$ is
\begin{equation}
P_{\infty}^{(E)}(S;\lambda)=\sum_{m\in\mathcal{M}}\frac{W_m^{(E)}(\lambda)}{\Omega(E;\lambda)}\,\delta\bigl(S-S_m^{(E)}(\lambda)\bigr).
\label{eq:Pinf_micro}
\end{equation}

\textbf{Proposition (sharp criterion; ``only translation'' degeneracy).}
Fix $E$ and the coarse-graining. Let $\mathcal{V}(\lambda)$ denote the multiset of accessible macrostate volumes $\{W_m^{(E)}(\lambda)\}_{m\in\mathcal{M}}$ (counting multiplicity).
\begin{enumerate}
  \item If there exists $c>0$ such that $\mathcal{V}(\lambda_2)=c\,\mathcal{V}(\lambda_1)$ (i.e.\ all macrostate volumes scale by the same factor, up to permutation), then $P_{\infty}^{(E)}(S;\lambda_2)=P_{\infty}^{(E)}(S-k_B\ln c;\lambda_1)$, i.e.\ the distribution changes only by translation along the entropy axis.
  \item Otherwise, $P_{\infty}^{(E)}(S;\lambda_2)$ is not a translate of $P_{\infty}^{(E)}(S;\lambda_1)$; the distribution changes structurally.
\end{enumerate}

\textit{Proof.}
Let $M$ be the random macrostate with $\mathbb{P}(M=m)=\pi_m^{(E)}(\lambda)$ and set $X_\lambda:=W_M^{(E)}(\lambda)$. Then $S=k_B\ln(X_\lambda/W_0)$ and \eqref{eq:Pinf_micro} is the law of $S$. If $W_m^{(E)}(\lambda_2)=c\,W_{\sigma(m)}^{(E)}(\lambda_1)$ for some permutation $\sigma$, then $X_{\lambda_2}\overset{d}{=}c\,X_{\lambda_1}$, hence $S_{\lambda_2}\overset{d}{=}S_{\lambda_1}+k_B\ln c$, which is the claimed translation. Conversely, if $P_{\infty}^{(E)}(S;\lambda_2)$ were a translate of $P_{\infty}^{(E)}(S;\lambda_1)$ by $\Delta$, then the distribution of $X_{\lambda_2}=W_0 e^{S/k_B}$ would be that of $e^{\Delta/k_B}X_{\lambda_1}$, implying $\mathcal{V}(\lambda_2)=e^{\Delta/k_B}\mathcal{V}(\lambda_1)$ up to permutation. \hfill $\square$

\paragraph{Canonical mixture.}
The canonical energy density is $P_\beta(E;\lambda)=\Omega(E;\lambda)\,e^{-\beta E}/Z(\lambda)$ with $Z(\lambda)=\int\mathrm{d}E\;\Omega(E;\lambda)\,e^{-\beta E}$. The canonical long-time entropy distribution is the mixture
\begin{equation}
P_{\infty,\beta}(S;\lambda)=\int\mathrm{d}E\;P_\beta(E;\lambda)\,P_{\infty}^{(E)}(S;\lambda).
\end{equation}
Changing $\lambda$ changes $W_m^{(E)}(\lambda)$ and $\Omega(E;\lambda)$, hence $P_{\infty}^{(E)}(S;\lambda)$ and $P_{\infty,\beta}(S;\lambda)$. The proposition above characterises exactly when the change is only a translation along the $S$-axis versus a structural change.

\textbf{Thus, in classical mechanics, constraints change the system's operating characteristics (the accessible phase space and the Hamiltonian) and reshape the entropy distribution.} This completes the classical proof of (i) and (ii) from the four axioms alone. No second law is used in this derivation.

\section{Cosmology}
\label{sec:cosmology}

Cosmology provides a global setting in which the arrow of time and the entropy distribution are manifestly constraint-dependent and initial-condition dependent.

\subsection{Past hypothesis and cosmological initial conditions}

The observed thermodynamic arrow of the universe (e.g.\ expansion, structure formation, radiation-matter transition) is often attributed to a \textbf{past hypothesis}: the (observable) universe is assumed to have been in a state of very low entropy (e.g.\ a homogeneous, low-entropy initial slice). The past hypothesis is a \emph{postulated} constraint on initial conditions (it is not derived from the equations of motion; it is imposed to match observational cosmology)~\cite{past}. This is not a law that ``entropy must increase''; it is a \textbf{constraint on initial conditions}. The entropy at later times is then determined by (i) this initial constraint, (ii) the dynamics (Einstein field equations plus matter field equations), and (iii) the cosmological parameters (e.g.\ $\Lambda$, spatial curvature, topology). Thus, \textbf{the cosmic arrow is imposed by the choice of initial condition (and the constraint that the initial state lies in a particular class of states), not by a universal law of entropy increase.} Entropy has no intrinsic direction; the direction we observe is that of the \emph{particular} solution selected by the past hypothesis.

\subsection{Horizons and coarse-graining}

In cosmology, observable regions are limited by horizons (particle horizon, event horizon). The entropy one assigns to ``the universe'' or to a patch depends on \textbf{which region is observed} (a constraint) and on the coarse-graining (e.g.\ hydrodynamic fields, galaxy distribution). Different choices of patch or coarse-graining yield different entropy histories. Thus, \textbf{constraints (horizon structure, choice of subsystem, coarse-graining) reshape the effective entropy distribution} in the cosmological context. There is no unique ``cosmic entropy'' independent of these choices.

\subsection{Implications for the main conclusions}

In cosmology, (i) \textbf{entropy has no intrinsic direction}---the arrow is fixed by the past hypothesis and the dynamics, not by a standalone entropy law; (ii) \textbf{constraints (initial conditions, topology, $\Lambda$, horizons) change the system's operating characteristics and reshape the entropy distribution} over cosmic time. This reinforces the main conclusions of \texttt{entropy.tex} and of this document in the setting of the universe as a whole.

\section{Quantum mechanics}
\label{sec:QM}

\subsection{Wigner time reversal and the quantum mirror-state argument}

In quantum mechanics, the phase-space microstate $\Gamma(t)$ is replaced by a state vector $|\psi(t)\rangle$ (or a density matrix $\rho(t)$). Time reversal is represented by an antiunitary operator $\Theta$ (Wigner's $T$~\cite{wigner}) satisfying $\Theta i = -i\Theta$, with $\Theta^2 = \pm \mathbf{1}$ (for integer spin, $\Theta^2=(-1)^{2s}$). For a time-reversal invariant Hamiltonian $H$ (e.g.\ $H$ with no magnetic field or spin-orbit terms that break $T$), $\Theta H \Theta^\dagger = H$, and if $|\psi_A(t)\rangle$ is a solution of the Schr\"odinger equation, then the mirror state $|\psi_B(t)\rangle := \Theta |\psi_A(2t_0-t)\rangle$ is also a solution. We consider a \emph{$T$-symmetric coarse-grained entropy}: an entropy functional or observational entropy such that $S(\Theta\rho\Theta^\dagger)=S(\rho)$ (e.g.\ macrostates that are mapped to themselves by $\Theta$, or the entropy of a reduced state under a $T$-symmetric partition). Admissible coarse-grainings are those for which the macrostate decomposition (or the set of projectors) is invariant under $\mathcal{T}$ (classical) or $\Theta$ (quantum), so that the mirror state lies in the same macrostate as the original at the same instant; this is the standard choice in statistical mechanics. For pure states the full-system von Neumann entropy is zero; the argument therefore applies to such a coarse-grained entropy. If one imposed a universal law ``entropy does not decrease forward in time'' for \emph{every} initial state, then applying it to both $|\psi_A(t_0)\rangle$ and $|\psi_B(t_0)\rangle = \Theta|\psi_A(t_0)\rangle$ would again force entropy to be a two-sided local minimum at every time, hence constant. This is the direct quantum analogue of the classical mirror-state construction (Sec.~\ref{sec:classical}). Thus, \textbf{under $T$-invariant quantum dynamics, entropy has no universal intrinsic direction.}

Constraints enter via the Hamiltonian $H(\lambda)$ (e.g.\ confining potential, magnetic field) or the accessible Hilbert subspace (e.g.\ projectors $\Pi_{\mathcal{A}(\lambda)}$). If the coarse-graining is $T$-symmetric, the conclusion holds. The long-time state under $H(\lambda)$ is determined by the eigenbasis and the invariant measure: for a closed system, the diagonal ensemble in the energy eigenbasis (or microcanonical/canonical in the appropriate limit); for a system in contact with a bath, the reduced equilibrium state. Thus \textbf{constraints $\lambda$ reshape the effective entropy distribution} in the same way as in the classical case.

\subsection{Time-reversal violation in quantum mechanics}

If the Hamiltonian violates time-reversal symmetry (e.g.\ $H$ includes a $T$-odd term such as a static magnetic field, or effective CP-violating terms), then $\Theta H \Theta^\dagger \neq H$, and the mirror state $\Theta|\psi_A(2t_0-t)\rangle$ is \emph{not} in general a solution of the same $H$. The mirror-state \emph{reductio} then no longer forces entropy to be constant along every trajectory, because the ``mirror'' trajectory is not a solution of the same dynamics. In that case, an arrow of time can arise from the \emph{breaking} of $T$, not from entropy itself. The conclusion is strengthened: \textbf{when $T$ is violated, the temporal arrow is imposed by the dynamics (or the constraint that breaks $T$), not by a fundamental law of entropy increase.} Entropy remains a derived quantity whose distribution depends on $H(\lambda)$ and the initial ensemble.

\subsection{Quantum entanglement and thermodynamic entropy}

Quantum entanglement introduces a direct link between \emph{constraints} (e.g.\ which subsystems are observed, which degrees of freedom are traced out) and the \emph{entropy} that appears in thermodynamics. For a bipartite system in a pure state $|\Psi_{AB}\rangle$, the reduced states $\rho_A = \mathrm{tr}_B |\Psi_{AB}\rangle\langle\Psi_{AB}|$ and $\rho_B = \mathrm{tr}_A |\Psi_{AB}\rangle\langle\Psi_{AB}|$ have von Neumann entropies $S(\rho_A) = S(\rho_B)$ (entanglement entropy). This entropy is \emph{not} a property of the full system (which has zero von Neumann entropy) but of the \emph{choice of partition} (constraint: what is ``system'' vs ``environment''). Changing the partition or the constraint (e.g.\ coupling to a bath, measuring one subsystem) changes the effective entropy. In nonequilibrium settings, the thermodynamic cost of measurement and feedback (e.g.\ in Maxwell's demon setups) is determined by the correlation structure and the constraint (which degrees of freedom are controlled). Thus, \textbf{constraints (partition, coupling, measurement) determine the entropy that appears in the thermodynamic description; entanglement thermodynamics is a clear instance of ``constraints reshape the entropy distribution.''}

\section{Particle physics: T- and CP-violation}
\label{sec:particle}

In the standard model of particle physics, the combined operation $CPT$ is an exact symmetry of any local, Lorentz-invariant, unitary quantum field theory~\cite{cpt}. Time reversal $T$ and $CP$ are \emph{not} exact: $T$-violation has been observed (e.g.\ in the neutral kaon system, $K^0$--$\bar{K}^0$ mixing and decay), and $CP$-violation is well established. The important point for our proof is:

\begin{itemize}
  \item If the \emph{fundamental} dynamics were $T$-symmetric, the mirror-state argument would apply and entropy could not have a universal arrow.
  \item The observed $T$- (and $CP$-) violation is a \emph{specific} feature of the weak sector (CKM matrix, etc.). It provides a \emph{microscopic} arrow (e.g.\ preference for certain decay directions) that can, in principle, be used to define a temporal orientation. This arrow is \emph{not} equivalent to ``entropy always increases''; it is a constraint or structure in the Lagrangian that selects a direction. The thermodynamic arrow in macroscopic systems (e.g.\ in the early universe or in particle detectors) then arises from the \emph{combination} of this microscopic violation with initial conditions and coarse-graining (which degrees of freedom are traced out). Thus, \textbf{the arrow is again imposed by dynamics and constraints (including the choice of coarse-graining and the initial state), not by a standalone law of entropy.} In particle-physics contexts (e.g.\ early-universe thermodynamics, detectors), the effective entropy and its distribution are likewise determined by \textbf{constraints}: initial state, choice of subsystem or coarse-graining (which degrees of freedom are observed or traced out), and the experimental setup. So (ii) also holds: constraints reshape the entropy distribution.
\end{itemize}

\section{General relativity: self-gravitating systems and black holes}
\label{sec:GR}

\subsection{Negative heat capacity of self-gravitating systems}
\label{sec:GR:negativeC}

Self-gravitating systems (e.g.\ a star, a globular cluster), in Newtonian gravity or in general relativity, exhibit \textbf{negative heat capacity} in a certain regime: $C = \partial E / \partial T < 0$ (in the Newtonian context this is related to the Antonov instability and the gravothermal catastrophe~\cite{antonov}). This is a consequence of the virial theorem and the long-range, attractive nature of gravity: adding energy can increase the kinetic energy and the ``temperature'' while the system expands and gravitational potential energy increases, so total energy $E$ can increase while the system cools. As a result:
\begin{itemize}
  \item The \emph{canonical} ensemble (fixed $T$) is ill-defined or unstable for such systems in the negative-$C$ regime: the partition function diverges or the equilibrium is not a maximum of the free energy. The long-time behaviour is determined by \textbf{constraints} such as total energy $E$, total angular momentum, and the boundary conditions (e.g.\ box size, presence of a bath in a limited region).
  \item The \emph{microcanonical} ensemble (fixed $E$) is the natural one; the entropy $S(E)$ and the entropy distribution depend on the constraint (e.g.\ whether the system is isolated, in a box, or coupled to a reservoir in a restricted way). Thus, \textbf{constraints (gravity itself, plus boundaries and coupling) literally define the thermodynamic description and reshape the entropy distribution;} there is no universal ``canonical'' entropy that applies regardless of constraints.
\end{itemize}

This is a direct analogue of the main conclusion: (i) there is no universal entropy-increase law (the arrow is set by constraints and initial conditions); (ii) \textbf{constraints change the system's operating characteristics} (here, the very stability and the appropriate ensemble) \textbf{and reshape the entropy distribution} (microcanonical vs canonical, and the form of $S(E)$).

\subsection{Black-hole entropy and constraints}
\label{sec:GR:BH}

Black-hole thermodynamics assigns an entropy $S_{\mathrm{BH}} = k_B A/(4 \ell_P^2)$ (Bekenstein--Hawking~\cite{bekenstein,hawking}), where $A$ is the horizon area and $\ell_P=\sqrt{\hbar G/c^3}$ is the Planck length. The horizon is a \textbf{constraint}: it defines the accessible region for external observers and the Hilbert space (or phase space) of the effective theory outside the hole. Different constraints (e.g.\ different horizon geometries, different topologies, presence of charge or angular momentum) yield different $A$ and hence different $S_{\mathrm{BH}}$. The entropy is not a universal function of energy alone but of the \emph{constraint} (the geometry and the Einstein equations that determine it). Thus, \textbf{constraints (horizon, topology, conserved charges) determine the entropy;} again, constraints reshape the entropy distribution (here, the effective thermodynamic description of the system).

Moreover, the information paradox and its resolutions (e.g.\ holographic duality) emphasise that the \emph{coarse-graining} (what an external observer can measure) is constraint-dependent; the entropy one ascribes to the black hole depends on the constraint (e.g.\ which degrees of freedom are traced out). This aligns with the view that entropy is a constraint-dependent distribution, not a universal monotonic function of time. Within \emph{semiclassical} general relativity, the conclusions (i) and (ii) hold as stated: there is no universal entropy-increase law (the arrow is from constraints and initial conditions), and constraints (horizon, geometry, coarse-graining) reshape the entropy distribution; possible modifications in a full quantum-gravity regime are addressed in Sec.~\ref{sec:QG}.

\section{Nonequilibrium statistical mechanics}
\label{sec:noneq}

\subsection{Fluctuation theorems}
\label{sec:noneq:FT}

In nonequilibrium statistical mechanics, \textbf{fluctuation theorems} (e.g.\ Crooks~\cite{crooks}, Evans--Searles~\cite{evans} for entropy production; Jarzynski~\cite{jarzynski} for work and free energy) relate the probability of forward and reverse trajectories and the statistics of \emph{entropy production} (or work). All rely on initial equilibrium (or a stated ensemble) and a prescribed protocol---i.e.\ constraints. Under the conditions of the Crooks~\cite{crooks} (or Evans--Searles~\cite{evans}) fluctuation theorem---time-reversal invariant microscopic dynamics (or stochastic dynamics such as Langevin that satisfy the same $T$-invariance and detailed-balance assumptions at the level at which the theorem is stated), \emph{initial equilibrium} (or a stated initial ensemble), and a \emph{driving protocol} $\lambda(t)$ that is time-reversal symmetric in the sense of the theorem (so that the reverse protocol is well-defined)---the probability of observing a trajectory with entropy production $\Delta S$ is related to the probability of the time-reversed trajectory with entropy production $-\Delta S$:
\[
\frac{P(\Delta S)}{P(-\Delta S)} = e^{\Delta S / k_B}.
\]
Thus, \emph{negative} entropy production is possible (though exponentially rare for large $|\Delta S|$); the ``second law'' is a statistical statement that holds on average or for typical trajectories, not a universal trajectory-wise law. The arrow of time in these theorems comes from the \textbf{initial condition} (e.g.\ equilibrium at $t=0$) and/or the \textbf{driving protocol} $\lambda(t)$ (constraint as a function of time). So: \textbf{entropy production is a fluctuating quantity; its distribution is determined by the constraint (the protocol and the initial ensemble), not by a universal law that entropy must increase.} This is fully consistent with the main conclusion that entropy has no intrinsic direction and that constraints reshape the entropy (and entropy-production) distribution.

\subsection{Constraints as control parameters}

In stochastic thermodynamics and nonequilibrium physics, the \textbf{control parameters} $\lambda(t)$ (e.g.\ time-dependent potential, stiffness of an optical trap, coupling to reservoirs) play the role of constraints. The steady-state or long-time distribution of the system (and hence of any coarse-grained entropy) depends on $\lambda$. Large-deviation principles describe how the probability of entropy production (or other observables) behaves; the rate function and the dominant paths depend on $\lambda$. Thus, \textbf{constraints $\lambda$ change the system's operating characteristics (the effective dynamics, the steady state) and reshape the distribution of entropy and entropy production.} No additional assumption of a universal entropy-increase law is required; the behaviour is derived from the dynamics and the constraints.

\section{Further domains: condensed matter, quantum field theory, open quantum systems}
\label{sec:further}

\subsection{Condensed matter and many-body physics}

In condensed matter and statistical many-body physics, the ``system'' is defined by \textbf{constraints}: lattice geometry, boundary conditions, external fields, and coupling to baths. The thermodynamic limit (volume $\to \infty$, density fixed) and the choice of ensemble (canonical, grand canonical) are constraints that determine the phase diagram and the entropy (or free energy) as a function of state variables. Phase transitions (e.g.\ ferromagnetic, superconducting) are regime changes induced by varying a control parameter (temperature, field, doping), i.e.\ by changing $\lambda$. The entropy and its distribution in the critical region are constraint-dependent; there is no universal entropy-increase law that governs the dynamics. Time-reversal symmetry is typically present in the microscopic Hamiltonian when $T$-odd terms (e.g.\ external magnetic field, magnetic order) or explicit coupling to an unresolved environment are absent; the mirror-state argument therefore applies unless $T$ is broken. \textbf{Thus, in condensed matter, constraints (lattice, boundaries, fields, ensemble) change the system's operating characteristics and reshape the entropy (and free-energy) landscape;} entropy has no intrinsic direction independent of these constraints.

\subsection{Quantum field theory}

In quantum field theory (QFT), the dynamics are given by the action and the path integral (or operator formalism). Time-reversal symmetry can be defined for the fields; when it holds, the same mirror-state logic applies to the evolution of field configurations. Constraints enter as boundary conditions, sources, and the choice of observable (which composite operators or subsystems are traced out). The entropy of a spatial region (e.g.\ entanglement entropy across a surface, or thermodynamic entropy of a subsystem) is constraint-dependent: it depends on the region and the vacuum or state. In thermal QFT, the equilibrium state and the entropy are determined by the Hamiltonian (and any chemical potentials) and the boundary conditions---again, constraints determine the entropy distribution. $T$-violation in the Lagrangian (e.g.\ $\theta$-term in QCD, or CP violation in the weak sector) selects a direction from the dynamics, not from a law of entropy. \textbf{Thus, in QFT, constraints (sources, boundaries, region of observation) reshape the entropy; entropy has no universal arrow except as imposed by $T$-violation or initial conditions.}

\subsection{Open quantum systems (Markovian)}

In open quantum systems, the system is coupled to an environment (bath). The \textbf{constraints} are the system--bath partition, the coupling Hamiltonian, and the initial state of the bath. The reduced dynamics (e.g.\ master equation, Lindblad form) and the steady state depend on these constraints. The entropy of the system (e.g.\ von Neumann entropy of the reduced state) is not a property of the full closed system but of the chosen partition and the coarse-graining (tracing out the bath). Under time-reversal invariant system--bath dynamics, the mirror-state argument applies to the full system; for the reduced system, the effective arrow can arise from the initial state of the bath (e.g.\ bath in equilibrium) and the choice of partition---again, constraints and initial conditions, not a standalone entropy law. \textbf{Thus, in open quantum systems, constraints (partition, coupling, bath state) determine the effective entropy and its evolution;} constraints reshape the entropy distribution.

\section{Nuclear physics, plasma physics, fluid mechanics, and information theory}
\label{sec:nuclear-plasma-fluid-info}

\subsection{Nuclear physics}

In nuclear physics, the system is defined by the \textbf{constraints}: the nuclear Hamiltonian (nuclear potential, Coulomb, spin-orbit), the number of nucleons $A$, charge $Z$, and the choice of ensemble (microcanonical at excitation energy $E$, canonical at temperature $T$, or grand canonical with chemical potentials). The level density $\rho(E)$ and the thermodynamic entropy $S(E) = k_B \ln \Omega(E)$ (or $S(T)$ in the canonical formulation) are determined by these constraints. Strong and electromagnetic interactions are $T$-invariant; weak interactions violate $T$ (and $CP$). Under $T$-invariant nuclear dynamics (strong/EM only), the mirror-state argument applies: a universal entropy arrow would force entropy to be constant on every trajectory, so \textbf{entropy has no intrinsic direction} in the $T$-invariant sector. When weak processes are included, the arrow is imposed by that breaking, not by a law of entropy. That entropy and its distribution over states are \textbf{constraint-dependent}~\cite{bohr}: different $A$, $Z$, potential parameters, or ensemble yield different $S(E)$ and $\rho(E)$. Thus, \textbf{(i) entropy has no intrinsic direction} (arrow from $T$-violation or initial conditions when present); \textbf{(ii) constraints (potential, $A$, $Z$, ensemble) change the operating characteristics and reshape the entropy (level-density) distribution.}

\subsection{Plasma physics}

In plasma physics (kinetic theory, Vlasov--Maxwell, or magnetohydrodynamics), the \textbf{constraints} are the confinement geometry, external fields (magnetic, electric), boundary conditions, and the choice of description (which moments or distribution function are retained). Entropy can be defined as the kinetic entropy (e.g.\ $-k_B \int f \ln f \,d^3x\,d^3v$ for phase-space distribution $f$, the standard Boltzmann-like functional) or in MHD as a fluid entropy. The microscopic dynamics (e.g.\ Lorentz force) are $T$-invariant; collisions or dissipative closures can break $T$. When they do, the arrow is imposed by that breaking, not by a law of entropy. Under $T$-invariant dynamics (e.g.\ collisionless Vlasov), the mirror-state logic applies to the phase-space distribution: no universal entropy arrow without contradicting $T$-invariance. The long-time or steady-state distribution of entropy is determined by the \textbf{constraints}: confinement, fields, boundaries, and initial conditions. Thus, \textbf{(i) entropy has no intrinsic direction} (arrow from dissipative terms, boundaries, or initial conditions when present); \textbf{(ii) constraints (confinement, fields, boundaries, closure) determine and reshape the entropy distribution.}

\subsection{Fluid mechanics}

In fluid mechanics (Euler or Navier--Stokes equations), the \textbf{constraints} are the domain (boundaries), body forces, viscosity, and initial and boundary conditions. Entropy appears in compressible flow (e.g.\ $s$ in the equation of state) and in the thermodynamic entropy of the fluid element. The Euler equations are $T$-invariant (inviscid; i.e.\ the dynamics are time-reversal invariant); the mirror-state argument then applies: reversing velocities at a time $t_0$ yields a solution that runs backward in time, so a universal ``entropy does not decrease'' would force entropy to be constant---no intrinsic arrow. The Navier--Stokes equations break $T$ (viscosity is dissipative); the arrow is imposed by that \emph{breaking}, not by a standalone entropy law. The entropy field $s(\mathbf{x},t)$ and its distribution (in space, in time, or over an ensemble of flows) are determined by \textbf{constraints}: geometry, forcing, Reynolds number, and initial and boundary data. Thus, \textbf{(i) entropy has no intrinsic direction} (Euler: mirror-state; Navier--Stokes: arrow from the dissipative term, not from a standalone entropy law); \textbf{(ii) constraints (boundaries, forcing, viscosity, initial conditions) reshape the entropy distribution} (the statistics of the entropy field).

\subsection{Information theory}

In information theory, \textbf{Shannon entropy} $H(X) = -\sum p_i \ln p_i$ (or differential entropy for continuous variables) is defined for a random variable or process; it has no built-in time direction---it is a functional of the \emph{distribution} $p$, which is fixed by the \textbf{constraints}: the alphabet, the partition of the outcome space, and the (possibly empirical) distribution. Changing the partition or the alphabet changes $H$. \textbf{Algorithmic (Kolmogorov) entropy} $K(x)$ (minimal description length of a string $x$) depends on the choice of universal machine and encoding---again a \textbf{constraint}. In the abstract definition there is no time variable; any temporal asymmetry in applications (e.g.\ communication, computation) is imposed by the \emph{constraints} (which process is run, initial state of the channel, encoding). The distribution of entropy (e.g.\ empirical entropy) in repeated trials is likewise constraint-dependent. Thus, \textbf{(i) entropy (Shannon or algorithmic) has no intrinsic direction}---any arrow in applications is from constraints (channel, protocol, initial state); \textbf{(ii) constraints (alphabet, partition, universal machine, encoding) define and reshape the entropy and its distribution.} Shannon and algorithmic entropy are therefore constraint-dependent by construction. This aligns with the main conclusions: entropy is constraint-dependent and has no universal law-like arrow.

\section{Extended scope: quantum gravity and non-Markovian open systems}
\label{sec:extended}

\subsection{Quantum gravity}
\label{sec:QG}

In quantum gravity (e.g.\ loop quantum gravity, causal set theory, string-theoretic or holographic formulations), the notion of entropy is still under debate: one may consider geometric entropy (horizon area), entanglement entropy across surfaces, or state-counting in a discrete Hilbert space. Time reversal (or its analogue in a diffeomorphism-invariant or background-independent theory) may or may not hold in a given formulation. When it does hold, a mirror-state-style argument can be applied to the effective dynamics and the chosen entropy functional, so that any \emph{universal} entropy arrow would again force entropy to be constant along dynamical orbits---incompatible with an observed arrow unless the arrow is attributed to \textbf{constraints} (e.g.\ boundary conditions, choice of embedding or foliation, or low-entropy initial condition). When $T$ (or its analogue) is broken by the theory, the arrow is imposed by that breaking, not by a law of entropy. In all current formulations, the entropy assigned to a region or to a horizon depends on \textbf{constraints}: which degrees of freedom are included, which coarse-graining or UV completion is used, and the boundary or initial data. We conclude that \textbf{within any formulation where entropy and time-reversal can be defined, (i) entropy has no intrinsic direction---any arrow comes from constraints or symmetry breaking---and (ii) constraints (boundaries, foliation, coarse-graining, initial conditions) reshape the entropy description.} The proof is necessarily schematic here because no single agreed definition of entropy or dynamics exists in quantum gravity (see standard reviews on loop quantum gravity, causal sets, string theory, holographic duality, etc.); the \emph{logic} of the argument (no universal monotonicity without contradicting $T$-invariance; constraint-dependence of the entropy distribution) extends to whatever candidate framework one adopts.

\subsection{Non-Markovian open systems}
\label{sec:nonMarkov}

When the system--bath coupling has memory (non-Markovian dynamics), the reduced dynamics are not in general given by a time-local master equation (e.g.\ not Lindblad form). The \textbf{constraints} remain the system--bath partition, the coupling, and the initial joint state (or initial correlations). The long-time or steady-state behaviour, when it exists, is still determined by these constraints and by the full unitary dynamics of the closed system. Under time-reversal invariant full dynamics, the mirror-state argument applies to the closed system; for the reduced system, any effective arrow arises from the \textbf{initial state} (including system--bath correlations) and the \textbf{choice of partition}---again constraints, not a universal entropy law. Entropy of the reduced state (e.g.\ von Neumann entropy) is explicitly constraint-dependent: different partitions or different initial correlations yield different entropy evolution. Thus, \textbf{in non-Markovian open systems, (i) entropy has no intrinsic direction (the arrow is from constraints/initial conditions or from $T$-breaking in the full dynamics), and (ii) constraints (partition, coupling, initial correlations, memory kernel) determine and reshape the effective entropy and its distribution.} This extends the open-quantum-systems conclusion to the non-Markovian regime without assuming Markovianity; see~\cite{breuer} for the standard framework.

\section{Synthesis and complete proof}
\label{sec:synthesis}

We now synthesise the foregoing into a single theoretical argument for the two main conclusions of \texttt{entropy.tex}. The classical case (Sec.~\ref{sec:classical}) is a complete proof from the four axioms; in each other domain the same logical scheme applies. In those domains the argument is a proof scheme that can be made formally precise by adopting the standard definitions of entropy, time reversal, and invariant (or long-time) measure for that domain.

\paragraph{Proof of (i): Entropy has no intrinsic direction.} In each domain below we use the standard notion of entropy for that domain. ``Universal'' means: holding for every system (or every trajectory) regardless of the choice of constraints. The classical case is a complete proof (Sec.~\ref{sec:classical}); the other domains follow the same logical scheme. (See Secs.~\ref{sec:classical}--\ref{sec:extended} and Sec.~\ref{sec:nuclear-plasma-fluid-info}.)
\begin{itemize}
  \item \textbf{Classical (Sec.~\ref{sec:classical}):} Under Axioms A1--A3, the mirror-state construction (with the Remark on continuous or discrete) shows that universal trajectory-wise or universal statistical monotonicity of entropy would imply entropy is constant on every trajectory; hence no universal arrow. Entropy is described by a distribution $P(S)$.
  \item \textbf{Cosmology:} The cosmic arrow is fixed by the past hypothesis (initial low-entropy state) and the dynamics, not by a law of entropy increase; the entropy distribution at later times is shaped by cosmological constraints (initial conditions, topology, horizons).
  \item \textbf{Quantum:} Under $T$-invariant $H$, the same argument holds with $\Theta|\psi(2t_0-t)\rangle$ for any $T$-symmetric coarse-grained entropy. Under $T$-violation, the arrow is imposed by the dynamics (the term that breaks $T$), not by entropy; entropy remains a derived, distributional quantity.
  \item \textbf{Particle physics:} $T$- and $CP$-violation provide a microscopic arrow; the thermodynamic arrow is a consequence of that violation plus initial conditions and coarse-graining (constraints), not a standalone entropy law.
  \item \textbf{General relativity:} In gravitational and cosmological contexts, the arrow is again set by initial and boundary conditions and by constraints (e.g.\ horizon, past hypothesis), not by a universal entropy-increase law; black-hole and cosmological entropy are constraint-dependent.
  \item \textbf{Nonequilibrium:} Fluctuation theorems show that entropy production is fluctuating; the ``second law'' is statistical and depends on initial conditions and protocol (constraints). There is no universal trajectory-wise entropy increase.
  \item \textbf{Condensed matter, QFT, open systems (Sec.~\ref{sec:further}):} In many-body and condensed matter physics, constraints (lattice, boundaries, fields, ensemble) fix the entropy landscape; in QFT, constraints (sources, boundaries, region) determine entropy; in open quantum systems, constraints (partition, coupling, bath) determine the effective entropy. In all cases the arrow is from dynamics and constraints, not from a universal entropy law.
  \item \textbf{Nuclear, plasma, fluid, information theory (Sec.~\ref{sec:nuclear-plasma-fluid-info}):} Nuclear: $T$-invariant strong/EM sector $\Rightarrow$ mirror-state; weak breaks $T$; arrow from constraints/violation. Plasma: $T$-invariant (e.g.\ Vlasov) $\Rightarrow$ no universal arrow; dissipative closures impose arrow. Fluid: Euler $\Rightarrow$ mirror-state; Navier--Stokes arrow from viscosity. Information theory: Shannon/algorithmic entropy has no intrinsic time; any arrow from constraints (channel, protocol, encoding).
  \item \textbf{Quantum gravity (Sec.~\ref{sec:QG}):} In any formulation where entropy and time-reversal (or its analogue) are defined, the same logic applies: no universal entropy arrow without contradicting $T$-invariance; any arrow is from constraints or symmetry breaking; constraints reshape the entropy description.
  \item \textbf{Non-Markovian open systems (Sec.~\ref{sec:nonMarkov}):} The full system is $T$-invariant; the reduced arrow comes from initial state and partition (constraints). Entropy of the reduced state is constraint-dependent; constraints reshape the effective entropy distribution.
\end{itemize}
Therefore, across all domains covered above (classical mechanics through quantum gravity and non-Markovian open systems, and nuclear physics, plasma physics, fluid mechanics, and information theory), \textbf{entropy has no intrinsic direction;} any arrow arises from constraints, initial conditions, or explicit symmetry breaking, not from a fundamental law of entropy.

\paragraph{Proof of (ii): Constraints change the system's operating characteristics and reshape the entropy distribution.} Again, ``entropy'' and ``distribution'' are those of the standard formulation in each domain; ``constraints'' are the parameters (including boundaries, initial conditions, and choice of coarse-graining) that fix the Hamiltonian, the accessible set, or the protocol. (See Secs.~\ref{sec:classical}--\ref{sec:extended} and Sec.~\ref{sec:nuclear-plasma-fluid-info}.)
\begin{itemize}
  \item \textbf{Classical (Sec.~\ref{sec:classical}):} $H(\Gamma;\lambda)$ and $\mathcal{A}(\lambda)$ determine the invariant measure and hence $P_{\infty}(S;\lambda)$; Proposition (sharp criterion) characterises translation vs structural change.
  \item \textbf{Cosmology (Sec.~\ref{sec:cosmology}):} Initial conditions, spatial topology, $\Lambda$, and horizon structure (constraints) determine the evolution of the effective entropy and its distribution over cosmic time.
  \item \textbf{Quantum (Sec.~\ref{sec:QM}):} $H(\lambda)$, projectors $\Pi_{\mathcal{A}(\lambda)}$, and partition (system vs environment) determine the effective entropy and its distribution; entanglement entropy is explicitly constraint-dependent.
  \item \textbf{General relativity (Sec.~\ref{sec:GR}):} Self-gravitating systems: constraints (total $E$, boundaries, coupling) determine whether microcanonical or canonical applies and the form of $S(E)$. Black holes: horizon and geometry (constraints) determine $S_{\mathrm{BH}}$.
  \item \textbf{Nonequilibrium (Sec.~\ref{sec:noneq}):} Control protocol $\lambda(t)$ and initial ensemble determine the steady-state and the large-deviation rate function for entropy production; constraints reshape the distribution.
  \item \textbf{Condensed matter, QFT, open systems (Sec.~\ref{sec:further}):} Lattice/fields/ensemble (condensed matter), sources/boundaries/region (QFT), and partition/coupling/bath (open systems) act as constraints that determine the entropy and its distribution.
  \item \textbf{Nuclear, plasma, fluid, information theory (Sec.~\ref{sec:nuclear-plasma-fluid-info}):} Nuclear: potential, $A$, $Z$, ensemble determine $S(E)$ and level density $\rho(E)$. Plasma: confinement, fields, boundaries determine kinetic/MHD entropy distribution. Fluid: boundaries, forcing, viscosity determine entropy field and its statistics. Information theory: alphabet, partition, universal machine, encoding define and reshape Shannon/algorithmic entropy and its distribution.
  \item \textbf{Quantum gravity (Sec.~\ref{sec:QG}):} In any formulation, entropy depends on constraints (boundaries, foliation, coarse-graining, initial conditions); constraints reshape the entropy description.
  \item \textbf{Non-Markovian open systems (Sec.~\ref{sec:nonMarkov}):} Partition, coupling, initial correlations, and memory kernel (constraints) determine the effective entropy and its evolution; constraints reshape the entropy distribution.
\end{itemize}
Therefore, in all domains covered (including nuclear physics, plasma physics, fluid mechanics, information theory, quantum gravity schematically, and non-Markovian open systems), \textbf{constraints change the system's operating characteristics and reshape the entropy distribution.}

\medskip
\noindent This completes the theoretical argument for the main conclusions of \texttt{entropy.tex}. The \emph{classical} part (Sec.~\ref{sec:classical}) is a complete, self-contained proof from the four axioms; in the extended domains (cosmology through information theory, quantum gravity, non-Markovian open systems) the same logical scheme applies as a proof scheme that can be made formally precise in each domain's standard formalism. The scope encompasses the settings described above; the quantum-gravity subsection is schematic because no single agreed framework exists. No appeal is made to any ``second law'' anywhere; the conclusions are derived solely from the stated axioms (classical) or the standard formulations of each extended domain.

\paragraph{Known physical domains and coverage.} The following are explicitly treated in this document: classical mechanics, cosmology, quantum mechanics, particle physics, general relativity, nonequilibrium statistical mechanics, condensed matter, quantum field theory, open quantum systems (Markovian and non-Markovian), quantum gravity (schematic), nuclear physics, plasma physics, fluid mechanics, information theory (Shannon and algorithmic). Domains that are not given dedicated sections but follow the same logical pattern (constraints and dynamics determine entropy; no universal entropy arrow) include: acoustics (wave equation $T$-invariant; entropy in irreversible processes from boundaries/dissipation); atmospheric and ocean physics (fluid/thermodynamic description, constraints as boundaries and forcing); chemical kinetics and reaction networks (constraints: rates, initial concentrations; entropy from statistical or thermodynamic formulation); biophysics (constraints: system boundaries, coarse-graining; same logic as open systems and statistical mechanics); thermodynamics of computation (Landauer, etc.: entropy cost constraint-dependent); metrology and measurement theory (which observables are recorded, coarse-graining); statistical inference and maximum-entropy methods (constraints: prior, data, choice of partition; entropy as uncertainty measure); optics and photonics (wave or photon description; constraints as boundaries and sources). Speculative or not yet fully formulated domains (e.g.\ quantum gravity beyond the schematic level, nonequilibrium quantum field theory) are noted in the text where relevant. Across all of these, (i) and (ii) hold: entropy has no intrinsic direction, and constraints reshape the entropy distribution.

\begin{thebibliography}{13}
\bibitem{entropy} Companion paper \texttt{entropy.tex}: four axioms, mirror-state construction, constraint-reshaping of $P_{\infty}(S;\lambda)$, and figures.
\bibitem{crooks} G.\,E. Crooks, \textit{J. Phys. Chem. B} \textbf{103}, 10677 (1999); entropy production fluctuation relation.
\bibitem{evans} D.\,J. Evans and D.\,J. Searles, \textit{Adv. Phys.} \textbf{51}, 1529 (2002); fluctuation theorems.
\bibitem{jarzynski} C. Jarzynski, \textit{Phys. Rev. Lett.} \textbf{78}, 2690 (1997); nonequilibrium work relation.
\bibitem{bekenstein} J.\,D. Bekenstein, \textit{Phys. Rev. D} \textbf{7}, 2333 (1973); black-hole entropy.
\bibitem{hawking} S.\,W. Hawking, \textit{Commun. Math. Phys.} \textbf{43}, 199 (1975); black-hole thermodynamics.
\bibitem{cpt} CPT theorem: e.g.\ R.\,F. Streater and A.\,S. Wightman, \textit{PCT, Spin and Statistics, and All That} (Princeton, 2000).
\bibitem{wigner} E.\,P. Wigner, \textit{G\"ottingen Nachr.} 546 (1932); time reversal in quantum mechanics.
\bibitem{past} Past hypothesis: e.g.\ D.\,Albert, \textit{Time and Chance} (Harvard, 2000); Boltzmann and modern cosmology.
\bibitem{antonov} V.\,A. Antonov, \textit{Vestn. Leningr. Univ.} \textbf{7}, 135 (1962); gravothermal instability (negative heat capacity in self-gravitating systems).
\bibitem{breuer} H.-P. Breuer and F. Petruccione, \textit{The Theory of Open Quantum Systems} (Oxford, 2002); non-Markovian and Markovian reduced dynamics.
\bibitem{bohr} A. Bohr and B. R. Mottelson, \textit{Nuclear Structure} (Benjamin, 1969); compound nucleus, level density, and statistical nuclear physics.
\end{thebibliography}

\end{document}
